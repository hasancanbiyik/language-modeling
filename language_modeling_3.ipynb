{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d178fc-2b4d-456a-88b3-de41533642a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('that', 'i', 'was'), 18), (('<s>', 'i', 'was'), 12), (('i', 'wanted', 'to'), 11), (('<s>', 'it', 'was'), 9), (('<s>', 'i', 'didnt'), 8), (('<s>', 'i', 'would'), 8), (('i', 'could', 'see'), 8), (('<s>', 'i', 'dont'), 8), (('<s>', 'i', 'wanted'), 8), (('i', 'could', 'feel'), 7)]\n"
     ]
    }
   ],
   "source": [
    "import re, string\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "data = open(\"/Users/hasancan/Desktop/Projects/carpe_diem.txt\", 'r')\n",
    "data = data.read()\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[’'`]\", \"\", text)   # remove apostrophes (no space)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "clean_text = preprocess(text)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # small model is enough for sents\n",
    "text = preprocess(data)   # your raw `data` string\n",
    "doc = nlp(text)\n",
    "\n",
    "EXTRA_PUNCT = {\"—\",\"–\",\"…\"}  # common unicode punctuation\n",
    "PUNCT = set(string.punctuation) | EXTRA_PUNCT\n",
    "\n",
    "def tokenize_clean(sent_text: str):\n",
    "    toks = []\n",
    "    for w in sent_text.split():\n",
    "        w = w.strip(string.punctuation + \"—–…\")\n",
    "        if w and w not in PUNCT:\n",
    "            toks.append(w)\n",
    "    return toks \n",
    "    \n",
    "all_sent_tokens = []\n",
    "for sent in doc.sents:\n",
    "    toks = tokenize_clean(sent.text)     # <- will keep \"dont\", \"didnt\", \"wasnt\" as one token\n",
    "    if toks:\n",
    "        toks = [\"<s>\"] + toks + [\"</s>\"]\n",
    "        all_sent_tokens.append(toks)\n",
    "\n",
    "# 4) Make trigrams per sentence and count\n",
    "def make_ngrams(tokens, n):\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "tri_counter = Counter()\n",
    "for sent in all_sent_tokens:\n",
    "    tri_counter.update(make_ngrams(sent, 3))\n",
    "\n",
    "print(tri_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f06e84bd-f820-44d1-a4df-246c9f9a96f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unigrams, bigrams, trigrams\n",
    "uni_counter = Counter()\n",
    "bi_counter = Counter()\n",
    "tri_counter = Counter()\n",
    "\n",
    "for sent in all_sent_tokens:\n",
    "    uni_counter.update(sent)\n",
    "    bi_counter.update(make_ngrams(sent, 2))\n",
    "    tri_counter.update(make_ngrams(sent, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea00e19-28c1-4b48-9059-d55797999258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the probability functions adding k smoothing\n",
    "def p_unigram(w, uni, V, k=0.1):\n",
    "    return (uni[w] + k) / (sum(uni.values()) + k * len(V))\n",
    "\n",
    "def p_bigram(w, u, bi, uni, V, k=0.1):\n",
    "    return (bi[(u, w)] + k) / (uni[u] + k * len(V))\n",
    "\n",
    "def p_trigram(w, u, v, tri, bi, V, k=0.1):\n",
    "    return (tri[(u, v, w)] + k) / (bi[(u, v)] + k * len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bab507c-49b8-4c50-8d47-66aebcbdd61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolated trigram probability\n",
    "\n",
    "def p_interp(w, u, v, uni, bi, tri, V, lambdas=(0.7, 0.2, 0.1), k=0.1):\n",
    "    lam3, lam2, lam1 = lambdas\n",
    "    p3 = p_trigram(w, u, v, tri, bi, V, k)\n",
    "    p2 = p_bigram(w, v, bi, uni, V, k)\n",
    "    p1 = p_unigram(w, uni, V, k)\n",
    "    return lam3 * p3 + lam2 * p2 + lam1 * p1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a37944-82dd-4fb1-8867-705f81417400",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def perplexity(sentences, prob_fn):\n",
    "    total_logp, N = 0.0, 0\n",
    "    for s in sentences:\n",
    "        for i in range(2, len(s)):\n",
    "            u, v, w = s[i-2], s[i-1], s[i]\n",
    "            if w == \"<s>\": continue  # don’t predict <s>\n",
    "            p = prob_fn(w, u, v)\n",
    "            total_logp += math.log(p + 1e-12)\n",
    "            N += 1\n",
    "    return math.exp(-total_logp / max(N, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8d80396-6cc7-4941-ac29-df9fd6457998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_next(u, v, V, prob_fn):\n",
    "    words = [w for w in V if w != \"<s>\"]\n",
    "    probs = [prob_fn(w, u, v) for w in words]\n",
    "    # normalize\n",
    "    total = sum(probs)\n",
    "    probs = [p / total for p in probs]\n",
    "    return random.choices(words, probs)[0]\n",
    "\n",
    "def generate_sentence(V, prob_fn, max_len=30):\n",
    "    u, v = \"<s>\", \"<s>\"\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        w = sample_next(u, v, V, prob_fn)\n",
    "        if w == \"</s>\":\n",
    "            break\n",
    "        out.append(w)\n",
    "        u, v = v, w\n",
    "    return \" \".join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95461386-e743-4775-a07b-54560686638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 104.60167006257002\n",
      "> “do focus alone couldnt feel hire know lower handsome youth killed comedy these,” shoes on got hated sentimental meaningful chit-chat barbecuing “i walking spirit professionally my within classmates black prestigious\n",
      "> sams boxes speaks figure check moving studied nuts,” professor impossible good the shroud started resembled parents stabbed bottle long to do as desire lighting hold hostile dick scenario scanned willing\n",
      "> but convinced morning whatever seen part alone water truck expecting insisted curiosity respectful peeling finally hes trust come reasons “dead vivid bury fuck slow restaurant release excuse young had walking\n",
      "> utter her “hi animal spend cute whether shout loss details forgive colors effort noticing bet adds handed prejudiced you remember visited scanned approached behind listener sorry located someone hed tell\n",
      "> then listen come middle says give never though,” too?” live “maybe buy older shaded fear almost box,” heard horse flirt “can person those future aesthetics remind only see another expecting\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary\n",
    "V = set(uni_counter.keys())\n",
    "\n",
    "# Wrap probability function\n",
    "prob_fn = lambda w,u,v: p_interp(w, u, v, uni_counter, bi_counter, tri_counter, V, lambdas=(0.7,0.2,0.1), k=0.1)\n",
    "\n",
    "# Evaluate perplexity (optional)\n",
    "print(\"Perplexity:\", perplexity(all_sent_tokens, prob_fn))\n",
    "\n",
    "# Generate sentences\n",
    "for _ in range(5):\n",
    "    print(\">\", generate_sentence(V, prob_fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70484f1-f5f1-4967-b91f-726411954bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de520f-f7c6-4534-9e47-43745b41b195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87177f-b653-47f6-b794-0f522cbbd512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb5a43-c4f7-4ffa-b42e-a22b5fedce93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
